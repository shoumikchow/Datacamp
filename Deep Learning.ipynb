{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the image given below:\n",
    "![Single layer neural network](https://s3.amazonaws.com/assets.datacamp.com/production/course_3524/datasets/1_4.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = {'node_0': np.array([2, 4]), 'node_1': np.array([ 4, -5]), 'output': np.array([2, 7])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = np.array([3, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-39\n"
     ]
    }
   ],
   "source": [
    "# Calculate node 0 value: node_0_value\n",
    "node_0_value = (input_data * weights['node_0']).sum()\n",
    "\n",
    "# Calculate node 1 value: node_1_value\n",
    "node_1_value = (input_data * weights['node_1']).sum()\n",
    "\n",
    "# Put node values into array: hidden_layer_outputs\n",
    "hidden_layer_outputs = np.array([node_0_value, node_1_value])\n",
    "\n",
    "# Calculate output: output\n",
    "output = (hidden_layer_outputs * weights['output']).sum()\n",
    "\n",
    "# Print output\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction is -39, which is impossible.\n",
    "### Now we apply a ReLU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(input):\n",
    "    return max(0, input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52\n"
     ]
    }
   ],
   "source": [
    "# Calculate node 0 value: node_0_output\n",
    "node_0_input = (input_data * weights['node_0']).sum()\n",
    "node_0_output = relu(node_0_input)\n",
    "\n",
    "# Calculate node 1 value: node_1_output\n",
    "node_1_input = (input_data * weights['node_1']).sum()\n",
    "node_1_output = relu(node_1_input)\n",
    "\n",
    "# Put node values into array: hidden_layer_outputs\n",
    "hidden_layer_outputs = np.array([node_0_output, node_1_output])\n",
    "\n",
    "# Calculate model output (do not apply relu)\n",
    "model_output = (hidden_layer_outputs * weights['output']).sum()\n",
    "\n",
    "# Print model output\n",
    "print(model_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is a more realistic prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a deeper network such as this:\n",
    "![Deep neural network](https://s3.amazonaws.com/assets.datacamp.com/production/course_3524/datasets/ch1ex10.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = {'node_0_0': np.array([2, 4]),\n",
    " 'node_0_1': np.array([ 4, -5]),\n",
    " 'node_1_0': np.array([-1,  2]),\n",
    " 'node_1_1': np.array([1, 2]),\n",
    " 'output': np.array([2, 7])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "182\n"
     ]
    }
   ],
   "source": [
    "def predict_with_network(input_data):\n",
    "    # Calculate node 0 in the first hidden layer\n",
    "    node_0_0_input = (input_data * weights['node_0_0']).sum()\n",
    "    node_0_0_output = relu(node_0_0_input)\n",
    "\n",
    "    # Calculate node 1 in the first hidden layer\n",
    "    node_0_1_input = (input_data * weights['node_0_1']).sum()\n",
    "    node_0_1_output = relu(node_0_1_input)\n",
    "\n",
    "    # Put node values into array: hidden_0_outputs\n",
    "    hidden_0_outputs = np.array([node_0_0_output, node_0_1_output])\n",
    "\n",
    "    # Calculate node 0 in the second hidden layer\n",
    "    node_1_0_input = (hidden_0_outputs * weights['node_1_0']).sum()\n",
    "    node_1_0_output = relu(node_1_0_input)\n",
    "\n",
    "    # Calculate node 1 in the second hidden layer\n",
    "    node_1_1_input = (hidden_0_outputs * weights['node_1_1']).sum()\n",
    "    node_1_1_output = relu(node_1_1_input)\n",
    "\n",
    "    # Put node values into array: hidden_1_outputs\n",
    "    hidden_1_outputs = np.array([node_1_0_output, node_1_1_output])\n",
    "    \n",
    "    # Calculate output here: model_output\n",
    "    model_output = (hidden_1_outputs * weights['output']).sum()\n",
    "    \n",
    "    # Return model_output\n",
    "    return(model_output)\n",
    "\n",
    "output = predict_with_network(input_data)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read up on backprop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras from now:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For regression models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://assets.datacamp.com/production/course_1975/datasets/hourly_wages.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = df.iloc[:,1:].values # Selects all columns except for the first one and converts into np array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df.iloc[:, 0].values # Selects the first column and converts into np array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the number of columns in predictors: n_cols\n",
    "n_cols = predictors.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the model: model\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the first layer\n",
    "model.add(Dense(50, activation='relu', input_shape=(n_cols,)))\n",
    "\n",
    "# Add the second layer\n",
    "model.add(Dense(32, activation='relu'))\n",
    "\n",
    "# Add the output layer\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss function: mean_squared_error\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Verify that model contains information from compiling\n",
    "print(\"Loss function: \" + model.loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "534/534 [==============================] - 3s 6ms/step - loss: 31.9152\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f60fc4f52e8>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "model.fit(predictors, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For classification models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://assets.datacamp.com/production/course_1975/datasets/titanic_all_numeric.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = df.iloc[:,1:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the target to categorical:\n",
    "target = to_categorical(df['survived'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Categorical converts single column binaries into different columns. Sometimes called one-hot-encoding. Example:\n",
    "![categorical example](https://i.imgur.com/0L56xgm.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cols = predictors.shape[1]\n",
    "\n",
    "# Set up the model\n",
    "model = Sequential()\n",
    "\n",
    "# Add the first layer\n",
    "model.add(Dense(32, activation='relu', input_shape=(n_cols, )))\n",
    "\n",
    "# Add the output layer\n",
    "model.add(Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "891/891 [==============================] - 0s 133us/step - loss: 2.6280 - acc: 0.5791\n",
      "Epoch 2/10\n",
      "891/891 [==============================] - 0s 51us/step - loss: 1.0867 - acc: 0.6207\n",
      "Epoch 3/10\n",
      "891/891 [==============================] - 0s 52us/step - loss: 0.6507 - acc: 0.6712\n",
      "Epoch 4/10\n",
      "891/891 [==============================] - 0s 53us/step - loss: 0.6785 - acc: 0.6667\n",
      "Epoch 5/10\n",
      "891/891 [==============================] - 0s 54us/step - loss: 0.6236 - acc: 0.6801\n",
      "Epoch 6/10\n",
      "891/891 [==============================] - 0s 51us/step - loss: 0.5980 - acc: 0.6768\n",
      "Epoch 7/10\n",
      "891/891 [==============================] - 0s 50us/step - loss: 0.6033 - acc: 0.6869\n",
      "Epoch 8/10\n",
      "891/891 [==============================] - 0s 51us/step - loss: 0.6363 - acc: 0.6700\n",
      "Epoch 9/10\n",
      "891/891 [==============================] - 0s 49us/step - loss: 0.5981 - acc: 0.6947\n",
      "Epoch 10/10\n",
      "891/891 [==============================] - 0s 50us/step - loss: 0.6027 - acc: 0.6857\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f6160a5b978>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# categorical is a loss function that is usually used for classification problems. it is similar to log loss: lower, the better\n",
    "# output layer has separate node for each possible outcome and uses 'softmax' activation.\n",
    "# Softmax ensures prediction sum to 1 so it can be interpreted as probabilities.\n",
    "\n",
    "# Fit the model\n",
    "model.fit(predictors,target, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_data = np.array([[2, 34.0, 0, 0, 13.0, 1, False, 0, 0, 1],\n",
    "       [2, 31.0, 1, 1, 26.25, 0, False, 0, 0, 1],\n",
    "       [1, 11.0, 1, 2, 120.0, 1, False, 0, 0, 1],\n",
    "       [3, 0.42, 0, 1, 8.5167, 1, False, 1, 0, 0],\n",
    "       [3, 27.0, 0, 0, 6.975, 1, False, 0, 0, 1],\n",
    "       [3, 31.0, 0, 0, 7.775, 1, False, 0, 0, 1],\n",
    "       [1, 39.0, 0, 0, 0.0, 1, False, 0, 0, 1],\n",
    "       [3, 18.0, 0, 0, 7.775, 0, False, 0, 0, 1],\n",
    "       [2, 39.0, 0, 0, 13.0, 1, False, 0, 0, 1],\n",
    "       [1, 33.0, 1, 0, 53.1, 0, False, 0, 0, 1],\n",
    "       [3, 26.0, 0, 0, 7.8875, 1, False, 0, 0, 1],\n",
    "       [3, 39.0, 0, 0, 24.15, 1, False, 0, 0, 1],\n",
    "       [2, 35.0, 0, 0, 10.5, 1, False, 0, 0, 1],\n",
    "       [3, 6.0, 4, 2, 31.275, 0, False, 0, 0, 1],\n",
    "       [3, 30.5, 0, 0, 8.05, 1, False, 0, 0, 1],\n",
    "       [1, 29.69911764705882, 0, 0, 0.0, 1, True, 0, 0, 1],\n",
    "       [3, 23.0, 0, 0, 7.925, 0, False, 0, 0, 1],\n",
    "       [2, 31.0, 1, 1, 37.0042, 1, False, 1, 0, 0],\n",
    "       [3, 43.0, 0, 0, 6.45, 1, False, 0, 0, 1],\n",
    "       [3, 10.0, 3, 2, 27.9, 1, False, 0, 0, 1],\n",
    "       [1, 52.0, 1, 1, 93.5, 0, False, 0, 0, 1],\n",
    "       [3, 27.0, 0, 0, 8.6625, 1, False, 0, 0, 1],\n",
    "       [1, 38.0, 0, 0, 0.0, 1, False, 0, 0, 1],\n",
    "       [3, 27.0, 0, 1, 12.475, 0, False, 0, 0, 1],\n",
    "       [3, 2.0, 4, 1, 39.6875, 1, False, 0, 0, 1],\n",
    "       [3, 29.69911764705882, 0, 0, 6.95, 1, True, 0, 1, 0],\n",
    "       [3, 29.69911764705882, 0, 0, 56.4958, 1, True, 0, 0, 1],\n",
    "       [2, 1.0, 0, 2, 37.0042, 1, False, 1, 0, 0],\n",
    "       [3, 29.69911764705882, 0, 0, 7.75, 1, True, 0, 1, 0],\n",
    "       [1, 62.0, 0, 0, 80.0, 0, False, 0, 0, 0],\n",
    "       [3, 15.0, 1, 0, 14.4542, 0, False, 1, 0, 0],\n",
    "       [2, 0.83, 1, 1, 18.75, 1, False, 0, 0, 1],\n",
    "       [3, 29.69911764705882, 0, 0, 7.2292, 1, True, 1, 0, 0],\n",
    "       [3, 23.0, 0, 0, 7.8542, 1, False, 0, 0, 1],\n",
    "       [3, 18.0, 0, 0, 8.3, 1, False, 0, 0, 1],\n",
    "       [1, 39.0, 1, 1, 83.1583, 0, False, 1, 0, 0],\n",
    "       [3, 21.0, 0, 0, 8.6625, 1, False, 0, 0, 1],\n",
    "       [3, 29.69911764705882, 0, 0, 8.05, 1, True, 0, 0, 1],\n",
    "       [3, 32.0, 0, 0, 56.4958, 1, False, 0, 0, 1],\n",
    "       [1, 29.69911764705882, 0, 0, 29.7, 1, True, 1, 0, 0],\n",
    "       [3, 20.0, 0, 0, 7.925, 1, False, 0, 0, 1],\n",
    "       [2, 16.0, 0, 0, 10.5, 1, False, 0, 0, 1],\n",
    "       [1, 30.0, 0, 0, 31.0, 0, False, 1, 0, 0],\n",
    "       [3, 34.5, 0, 0, 6.4375, 1, False, 1, 0, 0],\n",
    "       [3, 17.0, 0, 0, 8.6625, 1, False, 0, 0, 1],\n",
    "       [3, 42.0, 0, 0, 7.55, 1, False, 0, 0, 1],\n",
    "       [3, 29.69911764705882, 8, 2, 69.55, 1, True, 0, 0, 1],\n",
    "       [3, 35.0, 0, 0, 7.8958, 1, False, 1, 0, 0],\n",
    "       [2, 28.0, 0, 1, 33.0, 1, False, 0, 0, 1],\n",
    "       [1, 29.69911764705882, 1, 0, 89.1042, 0, True, 1, 0, 0],\n",
    "       [3, 4.0, 4, 2, 31.275, 1, False, 0, 0, 1],\n",
    "       [3, 74.0, 0, 0, 7.775, 1, False, 0, 0, 1],\n",
    "       [3, 9.0, 1, 1, 15.2458, 0, False, 1, 0, 0],\n",
    "       [1, 16.0, 0, 1, 39.4, 0, False, 0, 0, 1],\n",
    "       [2, 44.0, 1, 0, 26.0, 0, False, 0, 0, 1],\n",
    "       [3, 18.0, 0, 1, 9.35, 0, False, 0, 0, 1],\n",
    "       [1, 45.0, 1, 1, 164.8667, 0, False, 0, 0, 1],\n",
    "       [1, 51.0, 0, 0, 26.55, 1, False, 0, 0, 1],\n",
    "       [3, 24.0, 0, 3, 19.2583, 0, False, 1, 0, 0],\n",
    "       [3, 29.69911764705882, 0, 0, 7.2292, 1, True, 1, 0, 0],\n",
    "       [3, 41.0, 2, 0, 14.1083, 1, False, 0, 0, 1],\n",
    "       [2, 21.0, 1, 0, 11.5, 1, False, 0, 0, 1],\n",
    "       [1, 48.0, 0, 0, 25.9292, 0, False, 0, 0, 1],\n",
    "       [3, 29.69911764705882, 8, 2, 69.55, 0, True, 0, 0, 1],\n",
    "       [2, 24.0, 0, 0, 13.0, 1, False, 0, 0, 1],\n",
    "       [2, 42.0, 0, 0, 13.0, 0, False, 0, 0, 1],\n",
    "       [2, 27.0, 1, 0, 13.8583, 0, False, 1, 0, 0],\n",
    "       [1, 31.0, 0, 0, 50.4958, 1, False, 0, 0, 1],\n",
    "       [3, 29.69911764705882, 0, 0, 9.5, 1, True, 0, 0, 1],\n",
    "       [3, 4.0, 1, 1, 11.1333, 1, False, 0, 0, 1],\n",
    "       [3, 26.0, 0, 0, 7.8958, 1, False, 0, 0, 1],\n",
    "       [1, 47.0, 1, 1, 52.5542, 0, False, 0, 0, 1],\n",
    "       [1, 33.0, 0, 0, 5.0, 1, False, 0, 0, 1],\n",
    "       [3, 47.0, 0, 0, 9.0, 1, False, 0, 0, 1],\n",
    "       [2, 28.0, 1, 0, 24.0, 0, False, 1, 0, 0],\n",
    "       [3, 15.0, 0, 0, 7.225, 0, False, 1, 0, 0],\n",
    "       [3, 20.0, 0, 0, 9.8458, 1, False, 0, 0, 1],\n",
    "       [3, 19.0, 0, 0, 7.8958, 1, False, 0, 0, 1],\n",
    "       [3, 29.69911764705882, 0, 0, 7.8958, 1, True, 0, 0, 1],\n",
    "       [1, 56.0, 0, 1, 83.1583, 0, False, 1, 0, 0],\n",
    "       [2, 25.0, 0, 1, 26.0, 0, False, 0, 0, 1],\n",
    "       [3, 33.0, 0, 0, 7.8958, 1, False, 0, 0, 1],\n",
    "       [3, 22.0, 0, 0, 10.5167, 0, False, 0, 0, 1],\n",
    "       [2, 28.0, 0, 0, 10.5, 1, False, 0, 0, 1],\n",
    "       [3, 25.0, 0, 0, 7.05, 1, False, 0, 0, 1],\n",
    "       [3, 39.0, 0, 5, 29.125, 0, False, 0, 1, 0],\n",
    "       [2, 27.0, 0, 0, 13.0, 1, False, 0, 0, 1],\n",
    "       [1, 19.0, 0, 0, 30.0, 0, False, 0, 0, 1],\n",
    "       [3, 29.69911764705882, 1, 2, 23.45, 0, True, 0, 0, 1],\n",
    "       [1, 26.0, 0, 0, 30.0, 1, False, 1, 0, 0],\n",
    "       [3, 32.0, 0, 0, 7.75, 1, False, 0, 1, 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.20259556 0.43545094 0.42149925 0.4048545  0.1624196  0.14798403\n",
      " 0.07984806 0.27291337 0.17386252 0.5113486  0.17480692 0.20588927\n",
      " 0.17628227 0.38025331 0.15237106 0.10223716 0.23850745 0.5359934\n",
      " 0.0901288  0.40488186 0.5155186  0.17538157 0.08356363 0.2921819\n",
      " 0.30858114 0.1619652  0.50937706 0.45408982 0.16802078 0.5323795\n",
      " 0.4437923  0.43519276 0.17586191 0.19150129 0.2266779  0.53148913\n",
      " 0.21064147 0.14383785 0.49748933 0.44799727 0.21031636 0.2932458\n",
      " 0.53793675 0.15729025 0.23689096 0.10095042 0.3798862  0.16552731\n",
      " 0.45339468 0.5578946  0.35081303 0.01813248 0.4690123  0.5020024\n",
      " 0.29093733 0.329468   0.5153979  0.22029817 0.53495157 0.17586191\n",
      " 0.17097919 0.2847773  0.28608888 0.37968746 0.259292   0.19807619\n",
      " 0.388724   0.5034087  0.1537382  0.40641272 0.1748715  0.5784662\n",
      " 0.15922835 0.09114861 0.46547037 0.35174364 0.22722048 0.21639854\n",
      " 0.14281678 0.51024616 0.4782658  0.13932283 0.27223763 0.21891119\n",
      " 0.17374934 0.55554646 0.24148932 0.50731003 0.4067525  0.50626093\n",
      " 0.1688529 ]\n"
     ]
    }
   ],
   "source": [
    "# Calculate predictions: predictions\n",
    "predictions = model.predict(pred_data)\n",
    "\n",
    "# Calculate predicted probability of survival: predicted_prob_true\n",
    "predicted_prob_true = predictions[:,1]\n",
    "\n",
    "# print predicted_prob_true\n",
    "print(predicted_prob_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine tuning Keras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://assets.datacamp.com/production/course_1975/datasets/titanic_all_numeric.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = df.iloc[:,1:].values\n",
    "target = to_categorical(df['survived'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 623 samples, validate on 268 samples\n",
      "Epoch 1/10\n",
      "623/623 [==============================] - 0s 238us/step - loss: 1.7117 - acc: 0.6437 - val_loss: 0.9958 - val_acc: 0.7201\n",
      "Epoch 2/10\n",
      "623/623 [==============================] - 0s 92us/step - loss: 1.1111 - acc: 0.6565 - val_loss: 0.6968 - val_acc: 0.5709\n",
      "Epoch 3/10\n",
      "623/623 [==============================] - 0s 88us/step - loss: 0.8365 - acc: 0.5795 - val_loss: 0.6491 - val_acc: 0.5896\n",
      "Epoch 4/10\n",
      "623/623 [==============================] - 0s 80us/step - loss: 0.7536 - acc: 0.6244 - val_loss: 0.6308 - val_acc: 0.6604\n",
      "Epoch 5/10\n",
      "623/623 [==============================] - 0s 93us/step - loss: 0.6596 - acc: 0.6388 - val_loss: 0.5798 - val_acc: 0.6828\n",
      "Epoch 6/10\n",
      "623/623 [==============================] - 0s 90us/step - loss: 0.6405 - acc: 0.6501 - val_loss: 0.5962 - val_acc: 0.6828\n",
      "Epoch 7/10\n",
      "623/623 [==============================] - 0s 86us/step - loss: 0.6214 - acc: 0.6774 - val_loss: 0.5461 - val_acc: 0.7052\n",
      "Epoch 8/10\n",
      "623/623 [==============================] - 0s 89us/step - loss: 0.6043 - acc: 0.6709 - val_loss: 0.5495 - val_acc: 0.7239\n",
      "Epoch 9/10\n",
      "623/623 [==============================] - 0s 86us/step - loss: 0.5938 - acc: 0.6934 - val_loss: 0.5456 - val_acc: 0.7351\n",
      "Epoch 10/10\n",
      "623/623 [==============================] - 0s 89us/step - loss: 0.5772 - acc: 0.6902 - val_loss: 0.5467 - val_acc: 0.7313\n"
     ]
    }
   ],
   "source": [
    "n_cols = predictors.shape[1]\n",
    "\n",
    "# Set up the model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(32, activation='relu', input_shape=(n_cols, )))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Fit the model\n",
    "hist = model.fit(predictors, target, epochs=10, validation_split=0.3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 623 samples, validate on 268 samples\n",
      "Epoch 1/30\n",
      "623/623 [==============================] - 0s 90us/step - loss: 0.5817 - acc: 0.7095 - val_loss: 0.5304 - val_acc: 0.7201\n",
      "Epoch 2/30\n",
      "623/623 [==============================] - 0s 87us/step - loss: 0.5663 - acc: 0.7207 - val_loss: 0.5394 - val_acc: 0.7500\n",
      "Epoch 3/30\n",
      "623/623 [==============================] - 0s 91us/step - loss: 0.5528 - acc: 0.7432 - val_loss: 0.5319 - val_acc: 0.7537\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f615b07c198>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define early_stopping_monitor\n",
    "early_stopping_monitor = EarlyStopping(patience=2)\n",
    "\n",
    "# Fit the model\n",
    "model.fit(predictors, target, epochs=30, validation_split=.3, callbacks=[early_stopping_monitor])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
